\chapter{Publishers and the Archive}

In the previous chapters, I have outlined the ways in which the archive, and critical notions of it, has shifted from a fixed and graspable entity to a suite of interconnected parts, constantly shifting and morphing and adapting to new information. This chapter hones in specifically on the newsroom archive, and the ways in which online publishers and legacy news outfits are dealing with their digital and digitized archives.

The archive has historically been known as ``the morgue'' to newsrooms; the stories in the archive are dead. But new technologies and conditions have lead to many recent attempts to reanimate the news archive. Nicole Levy wondered if 2014 is ``the year of the legacy media archive'' in a \emph{Capital New York} story about \emph{Time} magazine's new ``Vault''.\footnote{The Vault can be found at http://time.com/vault.} She points to \emph{The Nation}'s ``back issues'', \emph{The New Yorker}'s open archive collections, and the \emph{New York Times}' TimesMachine and @NYTArchives Twitter account as examples of old publishers endeavoring to use their rich histories to create something new.\autocite{}

The Times' celebrated \emph{Innovation Report}, an internal document leaked to the press in May 2014, closely features archives: ``Our rich archive offers one of our clearest advantages over new competitors\ldots[b]ut we rarely think to mine our archive, largely because we are so focused on news and new features,'' arguing that ``we can be both a daily newsletter and a library.'' They suggest that arts and culture content, more likely to be evergreen, could be organized ``more by relevance than by publication date,'' and the topic homepages could be treated more as guides than wires. The report goes on to enumerate successful experiments with repackaging old content in collections, organized by categories and themes. They even suggest a widget for easy collection creation by both reporters and readers. By creating ``no new articles, only new packaging,'' the Times can easily give new life to old stories.

What makes this moment rich for focusing on digital archives, and their potential value to publishers both old and new? What are these outfits' plans for measuring success? How can legacy media best engage their old archives, and how can digital media prepare itself for the archives of the future?

\section{Context in context}


\subsection{The Scoop Effect} % Dear lord find a better term for this

The time is ripe for news and history -- content and context, feeds and archive -- to collide. News outlets have long obsessed over the ``scoop'', being the first to break a story, and indeed these breaking stories still drive a great deal of traffic. But publishers are increasingly scooped in turn; stories break immediately on social media, rather than the next morning in the newspaper. % Can I coin a neologism for this? The "break effect" or something? So that I can keep referring to it in the next couple pages without driving myself crazy
This is having a profound effect on the research process and news lifecycle for both journalists and editors/strategists.

For journalists, it has increasingly destroyed the stereotypical image of the reporter with a notepad in city hall. The increasingly real-time nature of scooping has led to reporters scouring Twitter as much as being in the field; even communication with sources increasingly occurs via email or tweet. The increasing presence of ``explainer'' and ``data journalism'' likewise speaks to this need; reporters must to wade through massive amounts of information in fast, efficient ways in order to uncover possible news stories, which requires very strong digital research skills. These are skills that librarians have been practicing for centuries, and a well-organized and linked archive can help reporters immensely with this research process. The data journalists thus emerges as an amalgam of reporter and librarian.

For editors and newsroom strategists, it has shifted the role of the journalist and the news publisher to explainer, data-gatherer, and context-provider. Picture a newsworthy event occurring as the epicenter, and the reporting that occurs around it as a set of concentric circles around the event. Towards the center, one might find tweets, wire reports, and quick announcements. At the edge, there are longform pieces, explainers, multimedia work and data-oriented stories that help draw immediate events into larger phenomena. While the scoop remains crucial and breaking news draws traffic, news outlets can no longer serve as raw information providers, with no context. For a publisher to stand out, it is crucial to bring ongoing stories into a larger dialogue and conversation.

\subsection{Explainers}

This focus is not limited to legacy media, as the rise of ``explainer journalism'' and context-based reporting emerges as the other side of this coin. \emph{The Nation}'s editor and publisher Katrina vanden Heuvel suggests that ``a clever use of archives is kind of an explainer 2.0.''\autocite{} The goal is to provide knowledge, not news.

The concept of explaining the news is not new. A 2001 Pew Center survey of newspaper editors concluded that they wanted to be ``news explainers'' first and foremost, ahead of ``news breakers'' or ``investigative watchdogs.'' But in a 2008 article called ``National Explainer,'' Jay Rosen accused editors of not staying true to their mission: journalists are not good at explaining the news and providing context. Instead, they focus too much on incremental and episodic updates, many of which go over the head of readers who haven't been following. Rosen likens the process to pushing software updates to a computer that doesn't have the software installed.

Rosen argues that while journalists are paid to report the news and not explain it, they should also be giving background and context to larger stories. Journalists ``don’t do a very good job of talking about the beginning and what got us to this point where it became news,'' according to Alex Blumburg of \emph{This American Life}. Even the occasional explainer that gets it right ends up in the flow of the same old information; Rosen argues that explainers like David Leonhardt's credit crisis piece in the New York Times ``should have been a tool in the sidebar of every news story the Times did about the mortgage mess.'' The little ``what's this?'' link is ``not about web design. That's a whole new category in journalism that I fear we do not understand at all.''

Rosen also points out that such explainers are helpful for other reporters as well as the public, influencing news and information flow across the pipeline. A Times explainer, for instance, can reach a reporter who is informed by it as he or she interviews local officials. Calling it a ``scaffold of understanding,'' Rosen suggests that we ``start with clueless journalists'' in the path towards providing context, and went on to create explainthis.org, for people to admit what they don't know to journalists who are ``standing by.''\autocite{rosen_2008}

Explainthis.org, now defunct, was like a library reference desk, staffed by the public and monitored by journalists. A peer of StackOverflow and ancestor to Quora, it is organized around questions rather than topics, discussed by the public and monitored by journalists. It requires someone to be curious enough to ask the question, however. Rosen touts the ability of explainers to generate interest in a topic, but here we're already expected to be interested.

\subsection{The Future of Context}

At a South by Southwest panel in 2010 called ``Future of Context,'' Rosen outlined the reasons explanation is needed and why it wasn't taking off. He cited both design and institutional problems; the prestige and real-time excitement of breaking (rather than explaining) news, as well as the explainer format getting lost in the shuffle of other news items.\autocite{rosen_2010} Metrics like clicking, watching, and even spending time on a site are not measuring the level of understanding or knowledge gained.

The panel opened with NPR's Matt Thompson, owner of former contextual news blog newsless.org, arguing that we need more ``systemic information, not episodic info.'' Systemic information could include lists, charts, and maps that stay valuable well after the episodic news is irrelevant. Tristan Harris of Apture says, ``my background is computer science. You never do work that you can't re-use.'' He suggested an ``object-oriented'' approach to journalism with an eye towards sustainable, continuously updating tools and widgets that keep a reader informed. News is organized around stories rather than objects, resulting in streams rather than systems. A systemic, object-oriented approach to news places the context in the center.

The panel concluded with Harris suggesting that the New York Times has the power to sustain a wiki-like approach to journalism.

When Kramer asked ``how is this more than links?'' Thompson replied ``Links can be part of it.''


``The context should be the foundation. The systemic stuff should be what you can access first. The episodic stuff is what should be the more info. We “ghettoize” topics pages on our sites, by creating a topics section. When the public just finds just a random collection of links on a so-called topics page, “the quest for context everywhere is set back,” Thompson argues. What would a site look like if it were structured around systems instead of stories?

Journalists may think, we’re doing so much and now you want to provide context!? Think like an engineer. Make it an imperative to do work you can re-use to provide context. You can use that subduction plates info graphic again and again with every story you write about earthquakes. It’s redefining the notion of “today” value. You’re writing something TODAY that’s only appending something that’s already valuable. Engineers don’t do work they can’t re-use. Do work you can use next time.''

Chuck Peters, of the Cedar Rapids Gazette:

``I can’t see providing that context without changing how we create information in the first instance. Any factual element (photo, incident, quote, data, etc.) can be relevant to numerous contextual narratives. So each of those elements needs to both “stand on its own” and be tagged with as many potential relationships as possible…. We usually create information today in locked-down packaged articles, which block the easy flow of the elements between and among narratives.''

\subsection{Vox}

At the start of 2014, Ezra Klein left his position at the head of Washington Post's Wonkblog to start Vox, a news site that aimed to make context a first-class citizen of web journalism. Vox's mission: ``to create a site that's as good at explaining the world as it is at reporting on it.''\autocite{} Vox hopes to take a step back from the immediate news event and place it in a larger phenomenon. Taking the long view on stories also gives them an eye towards sustainability; Vox's topics are built around what they call ``card stacks.''\footnote{See http://www.vox.com/cardstacks.} Cards have titles like ``Everything you need to know about marijuana legalization,'' or ``9 facts about the Eurozone crisis,'' and each card is divided into question-driven subsections like ``What is marijuana decriminalization?'' Readers can navigate sequentially, or dive from question to question, going through Vox's explanations and photos. The final option is always the same: the ``Explore'' button takes the reader back to the top of the stacks.

The card stacks house a growing and morphing repository of knowledge. They are a public archive, like a Wiki but with more authorship intact. At the end of each card, Vox offers a link to email the author/curator of the card stack. For Vox reporters, starting a stack is also a pledge to maintain it. Vox also give a summary of changes made to the card (full versioning, they say, is coming soon).

The goal is not to replicate Wikipedia, but to offer another source with curated information. As was said in the South by Southwest panel, users don't want more information, they want the minimum; dropping a user into a Wikipedia page does not often serve well. A journalist-written Wikipedia can be written with standard journalistic guidelines, rather than Wikipedia's ``no original research'' rules.

Klein has Wikipedia in his sights, suggesting that ``I think it's weird that the news cedes so much ground to Wikipedia. That isn't true in other informational sectors.'' By combining incremental news with an evolving repository, Klein hopes to gain the best of both worlds: ``the card stacks add value to the news coverage. And the news coverage creates curiosity that leads people to the card stacks.'' This follows Rosen's idea that explaining the news can generate future interest in incremental updates. For Klein, ``the biggest source of waste is everything the journalist has written before today.''\autocite{nyt_vox_melding} ``It would be like a wiki page written by one person with a little attitude,'' Vox co-founder Melissa Bell explained.

For Klein, there is a distinct need, like Rosen saw, for a website that takes a step back and explains the news. In his words, ``The more folks in the media feel like it's beneath them to answer questions like ``What is marijuana?'' or ``What is Ukraine?'' the more we don't have to compete with them.''

Vox has accompanied other ``explainer'' and data-focused websites, like Nate Silver's FiveThirtyEight, and The New York Times' The Upshot. Soon after Vox's launch, Craig Silverman wrote ``Why Vox (and other news orgs) could use a librarian,'' suggesting that Vox had ``a huge challenge, due to the rapid decay of facts.''.\autocite{}  Some of these facts may not even be obviously newsworthy, such as if an academic research paper changes the conversation on Alzheimer's care. Who is going to keep everything up to date? ``Someone at Vox is going to need to know which card stacks to update when,'' and how to keep the explainers update with minimal maintenance.

\subsection{Libraries}

While someone needs to maintain all of these card stacks, it may not be a librarian. There are fewer and fewer librarians in newsrooms, which places their responsibilities increasingly on the reporter instead. Amy Disch, chair of the Special Libraries Association News Division, speaks to the traditional division of skills between reporter and librarian in the newsroom: ``We can find the information in a lot less time because we know how to drill down in a database. We know good sources to go to where you can quickly find information, so we can cut a lot of time for [reporters] and leave them to do what they do best, which is interviewing and writing. I have my specialty, and they have theirs.''\autocite{} Given that number of librarians in newsrooms is dwindling, are reporters picking up on this specialty?

Most legacy newsrooms have a library, but their librarians are ``a dying breed,'' with librarians getting laid off from a variety of institutions after the recession. Over 250 news librarians lost their jobs in the U.S. from 2007 to 2010, and membership in the Special Libraries Association News Division has steadily dwindled. The function of news libraries has even been shut down and outsourced to vendors like LexisNexis.

While the laying off of librarians is unfortunate, the shuttering of libraries is tragic. The massive, rich and rights-free information found in the news library is worth resurfacing and salvaging for every publisher. The closing of libraries also often closes the paper's research center, which hurts a newspaper in two ways. Not only will their research skills as an organization suffer, but they will also cease to be a steady provider of useful and updated information.

Old newspaper librarians were primarily tasked with archiving the newspaper itself, and not its online equivalents; some would have separate archiving teams or departments for the two products.

At a 2001 summit on news libraries, futurist Arthur Harkins suggested that in order to stay relevant, news librarians should ``leave the information management functions to automation'' and instead focus on ``the ability to put knowledge into context and to synthesize information.'' The librarians focused on solutions like structuring incoming stories, helping merge mixed media operations and create new revenue opportunities from older assets.

One major function of librarians was also to teach journalists research and technical skills; but many of these skills are expected of new journalists. Such reporters arrive with ample internet research skills, but little of the nuanced understanding of sources that a librarian brings to the table. Digital tools that aim to automate information management would do well to inject some of a librarian's nuance and knowledge of sources.

Finally, the librarian's task is largely to tag; to structure stories for future discoverability and reuse, by both journalists and the public. Many publishers, like Time and the Boston Globe, have lamented the loss of their manpower to manually tag all ongoing stories. 

Leslie Norman, former librarian at the Wall Street Journal, suggested, ``I see the news library as it once existed as probably dying, but in many newspapers, it's evolved into something else.'' 

Still, some libraries and cultural heritage organizations are making promising digital inroads into news. Old newspapers provide a rich archive of both historic stories and incidental ephemera like sports scores, weather reports, advertisements and small human interest stories. This gives historians a glimpse of a day, with the major phenomena of the day mixed in with everyday events.

Most of these projects are aimed towards the serious researcher, but they also point towards ways to engage casual browsers and fans of history. The National Library of Australia's Trove collection features 370 million resources; primarily, Australian newspapers ranging from 1803 to 1954.\footnote{http://help.nla.gov.au/trove/building-with-trove/api} Their API allows programmatic access, which in turn leads to the TroveNewsBot, an irreverent Twitter bot that can search the collection and yield a personalized result. Similarly, the Digital Public Library of America's DPLA Bot and British Library's Mechanical Curator both post random resources from their collection, aiming to inject a serendipitous sense of the past into the present.

Newspapers would do well to merge increasingly with digital cultural heritage institutions and library APIs. 

or they argue that ``the software newsrooms have adopted in the digital age has too often reinforced a workflow built around the old medium.''


\section{Why link?}

News publishers prove an ideal study for examining the potentials of hypertext archives. If we treat a newspaper as a proto-hypertextual document, it becomes apparent that online news might be a natural extension of reading the newspaper. Few readers go through a newspaper sequentially, paying equal attention to every article; instead the reader jumps around from page to page, skimming some sections for its raw information while reading longer pieces more deeply. A newspaper's front page reads like a website homepage, with snippets and teasers that aim to draw the reader deeper. A given page can hold several articles, and an interested reader might be distracted or intrigued by a ``related article'' next to the one he or she came to read. Some works are categorized into sections -- arts, sports, letters to the editor -- while others might be paired with a certain advertisement or reaction article. These examples point to the inherently interlinked nature of newspapers, and the endless potential for insightful metadata; newspapers might seem to naturally lend themselves to the digital world.

Newspapers are rich archival documents, because they store both ephemera and history. Journalists sometimes divide these types of news into ``stock'' and ``flow''; the constant stream of information built for \emph{right now}, versus the durable stuff, built to stand the test of time. A newspaper is a very complex design object with specific archival affordances; their irregular size, seriality, and great care in page placement make them ripe for unique forms of automated analysis. For some researchers, placement will be important (was an article’s headline on the first page? Above or below the fold? Was there an image, or a counterpoint article next to it?). Others could be examining the newspaper itself over time, rather than the contents within (for instance, did a paper’s writing style or ad placement change over the course of a decade?) Still others may be hoping to deep-dive into a particular story across various journals. In each case, we can glean information from where and when it was published on the page.

However, traditional newspapers have a major limitation: they cannot \emph{explicitly} link to other work in a structured and idiomatic way. Scholars have long relied on the footnote and bibliography to systematically track influence and dialogue, and networks of citations can be created out of them. The footnote has its limitations (as discussed earlier somewhere), % WHERE?? % % QUESTION: ARE THERE ANY DH PROJECTS TO REFERENCE HERE? Mapping citation networks in older documents? %
but newspapers don't even get footnotes. So while a newspaper's layout and seriality might afford a news story more insight than an academic article, its flatness and lack of citation conventions lead to limitations in computationally gathering insight from a newspaper archive.

Digital news publishing has the potential to change the conversation through the networks it creates; its hyperlinks, its embedded media, and the media that links \emph{to} it. Hyperlinks allow for a new standard of citation, reference, and context provision for news. At smaller scales, the link can even go beyond the footnote by linking in both directions, allowing readers to see who referenced the story; an old article in the New York Times, for instance, can link out to more recent related Times articles, other publishers or blogs that picked up on the story, or conversations in the Times forum or on Twitter. Linking offers great potential, not only for enlivening the reading experience, but also for creating a traceable dialogue that can improve a story's discoverability in the future.

\subsection{The structure of stories}

In technical terms, stories are usually objects in a database that have associated text, images and tags. In short, stories contain multitudes; they are an agglomeration of multimedia objects. Any link from one story to another must then refer to the story as a whole, rather than a salient part of that story (whether it be a certain paragraph or an interactive chart within it).

What is the atomic unit of information for news? It has traditionally been the article in a feed or stream, but Apture's Tristan Harris suggests that ``Because journalism is structured on the article, it doesn't accomodate the full extent of information we need.'' An article tends to pull paragraphs from one source, photos and charts from another; when we link to an article, we're not sure whether it's the article, photo or chart that matters. Data structures like Vox's card stack or Circa's cards showcase alternate ways to organize and reuse this information; by putting it in bite-sized chunks, each hopes to create a baseline repository to build upon rather than recreate from scratch every time.

This approach will require rethinking how we organize news items and structure stories. A ``story'' need not be a fresh new original piece of reporting every time; instead it can be a collection, ecosystem or dialogue of items. A journalist's goal should be not to \emph{write}, but to \emph{curate}, \emph{collect}, and \emph{contextualize} a news story. Thinking of a story as a collection or mash-up offers a new framework of a story as a highly linked entity, one that can start to organize itself.

% Explain in more detail here: Google has shown that organizing by link is easier than by taxonomy in the massive networked age. Shirky and Weinberger suggested that the tag should replace the fixed category. NYT Innovation Report also suggests that tags are crucial for their future as the paper of record (pp. 41-42).

% but as Debrouwere points out, even tags don't cut it. 

% Newsrooms have big collections of stories that link, reference, and embed tons of media. They also have smart entity recognition and linked data tools at their disposal. So -- especially as more newsroom librarians are laid off and cannot upkeep ongoing stories in the archive, why is tagging and text searching still the fundamental way to structure metadata and search for stories? %

Even once we assume that linking is a fundamental good for journalists, the problem remains of standardizing and developing a language \emph{for} linking, for this new affordance in citation and context provision.

% Anthony Grafton %  % Google books / Google scholar % % This should all probably be in a different place though %
The digital realm, unbound by physical juxtapositions, can not only add an arbitrary number of links, but it can link \emph{in both directions}. Where paper books can only take a reader back in time, pointing only to its sources, it cannot tell you who used it as a source in turn. This results in what network scientists call a ``directed'' network, rather than a bidirectional one. to adds to these links.
% Jaron Lanier: "You're throwing away all the best parts of a network" (or Weinberger? Barabasi?). "Could not have greater implications"

\subsection{How are publishers linking?}

Given these potentials, it might be surprising to find that many publishers are very reticent to link. Those who do have linking policies are often quite conservative.

% OVERVIEW OF LINKING POLICIES: NYT, BBC, Guardian, etc. % % Reference to next section where I explain more what they're doing %

Some of this is due to SEO; while no one knows exactly what Google's mercurial PageRank algorithm is doing, it's clear that links form a fundamental component (and as critics such as Clay Shirky have argued, relying on links rather than traditional categories and tags has been the crux of their success over competitors like Yahoo! and HotBot).\autocite{} Publishers are also wary of taking a reader away from their own website. But I'm also sure that much of the fear of links comes from inertia and tradition; since journalists never used to have a way to link, some don't see a need to start.

While many have debated the potentials and pitfalls of hyperlinking the news, I am proposing an additional wrinkle to the conversation; a smart use of linking is, to borrow Derrida's term, a \emph{pledge}, to better structure the news and keep archives continuously animated and relevant.

\subsection{Networking the news}

The first stage for any legacy publisher -- anyone that creates physical newspapers or magazines -- is to \emph{digitize} the archive. This tends to consist of scanning the pages of old publications, running OCR (optical character recognition) on each page, and exposing the results to a search interface for researchers and interested readers.

Most publishers have reached this stage; it is a crucial first step for enlivening the archive, but a physical record can often limit the digital equivalent's potentials. Digital versions of physical articles often do not leverage links and mixed media to the same effect. While a digital-native version of a print article might directly cite more sources or feature an intriguing interactive, these elements remain second-class citizens to the print article, which digital versions must remain faithful to. The Times' Innovation Report argues that by modeling their website and apps on their print structure, the Times ``ask[s] too much of readers.''

% Back up your archives! http://www.cjr.org/behind_the_news/minus_proper_archives_many_new.php. Many of these just rely on LexisNexis instead.

It is also telling that many of the digitization projects, begun decades ago, focused exclusively on salvaging the text. This ignores substantial information in the archive; especially images, which have long been seen as a way to monetize archives. % Add aside here about how images could be monetized? %
Some publishers have re-scanned their entire archive in order to capture the images that they ignored years ago.  % The NYT advertisement search % % Lily tried this; also that guy who went through and just got the images from old sources %

The second stage is to \emph{atomize} the archive; to break these scanned pages into their consituent parts. Given the newspaper's inherently hypertextual nature, this is a major challenge at any scale. What metadata is worth saving? The text, the subtext, the pictures? The photo or pullquote on the side?

I have been using the term ``linked'' or ``networked'' to describe the archive; but when legacy news publishers refer to a ``linked'' record in a digital archive, they are referring to the ability to link back to the scanned original source, where a database record can lead to a view of the ``original'' in PDF form. Some publishers do not even have linked records for their entire archive.

% Where to put monetization and paywall questions?

\section{Case Study: Time Vault}

% How is legacy media thinking about their physical archives? %

Legacy media has a rich trove of archives that have untapped potential to add explanation and context far beyond what newer digital outfits can create. The daunting challenge is to gain insight from archives at scale. Here I will trace the state of archives for legacy news publishers, and examine some of the efforts to improve it.

% NYT Innovation Report: there's value in your archive! But some legacy outlets are taking this the wrong way and just siloing it away and charging a few dollars per article. There's no doubt that the archive needs to ultimately produce value, and charging for old content is one option. It can even be a good stepping stone, but it is a shortsighted one.

% The Times Times Machine; Highrise; Topics pages; Semantic API; etc.

% "Long history" view tends to come from weekly columns or random forays by individual journalists. Always billed specifically as an archive dive/archival project. Historical and willfully nostalgic.
% But this does point to a place to start; some data is better structured and forms longer histories than others. e.g. history of Whitey Bulgur, Boston's bids for the Olympics, or neighborhood deep-dives.
% The problem: it needs to be framed outside of the "eating your news vegetables" framework

\section{Case Study: Vox cards? Quartz obsessions?}

% How is digital media thinking about the future? %

\section{Libraries and historical repositories}

% DPLA
% JSTOR
% PopUp archive -- brings up multimedia question
